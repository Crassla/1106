<!DOCTYPE html>

<html>

<head>
  <title>MACHINE LEARNING</title>
  <link rel="stylesheet" type="text/css" href="style.css">
  <meta language="english">
  <meta charset="UTF-8">
  <meta name="author" content="Alexandria Meyer">
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Rajdhani&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@100;300&display=swap" rel="stylesheet">
  <link rel="shortcut icon" href="images/favicon.ico?" sizes="16x16" type="image/x-icon">
</head>

<body>
  <header>
    <h1 class="title" style="font-size:3.5vw;"><a href="index.html">COMP501 Computing Technology in Society:<br>
        SUPERVISED MACHINE LEARNING</a></h1>
  </header>
  <div id=background>
    <nav>
      <h2 class="nav" style="font-size:1.25vw;"><a href="index.html">Home:</a></h2>
      <h2 class="nav" style="font-size:1.25vw;"><a href="topic.html">Topic:</a></h2>
      <h2 class="nav" style="font-size:1.25vw;"><a href="opportunities.html">Opportunities:</a></h2>
      <h2 class="nav" style="font-size:1.25vw;"><a href="risks.html">Risks:</a></h2>
      <h2 class="nav" style="font-size:1.25vw;"><a href="choices.html">Choices:</a></h2>
      <h2 class="nav" style="font-size:1.25vw;"><a href="ethics.html">Ethical Reflections:</a></h2>
      <h2 class="nav" style="font-size:1.25vw;"><a href="references.html">References:</a></h2>
      <h2 class="nav" style="font-size:1.25vw;"><a href="process_support.html">Process Support:</a></h2>
    </nav>
    <div id="content">
      <h2 style="font-size:2.15vw;" text-align="left">Alexandria's Ethical Reflection:</h2>
      <div class="box">
        <br>
        <h3>
          Supervised Machine Learning (SML) is being used more and more in everyday life. And systems -the
          opportunities- built off SML are being implemented in many different large-scale ways.<p></p>

          Examples of these are:<br>
          Tesla deploying road recognition to create self-driving cars. American prison systems trial SML algorithms
          such as facial recognition and data analysis to detect the likelihood of a freed prisoner committing a crime
          again. And cameras using facial recognition to check if a person has blinked in a photo.<p></p>

          But due to the independence and freedom with which the algorithms are allowed to work. These opportunities
          allow for a lot of risks.<p></p>

          The main risk related to SML is bias in data. This can cause the output from the algorithm to be biassed
          towards a certain outcome. Especially in the cases of neural networks as these normally outputs a yes or no
          response. E.g an image inputted is either a cat or not a cat. An example of this is in the American prison
          system’s risk assessments. A bias in the training data has caused the risk assessment to be racist against
          people of colour (Angwin et al., 2016).<p></p>

          In the ITP Code of ethics, it is stated “Members shall treat people with dignity, good faith and equality;
          without discrimination; and have consideration for the values and cultural sensitivities of all groups within
          the community affected by their work;”. Thus this is significant as it has impacted people’s lives greatly due
          to the discrimination this bias in training data has caused.<p></p>

          If people are allowed to continue creating SML algorithms without any care for the people it impacts, and if
          there is no check-in place to catch any bias in training data, this issue may be repeated. This is why I
          believe that there needs to be a code of ethics that every computer programmer and person working with these
          sorts of algorithms must sign.<p></p>

          I also believe that ethics papers should be incorporated and made compulsory in every course that teaches
          computer and data science. This will prevent situations such as these from occurring. And will protect against
          any, accidental or purposeful, harmful actions against our wider communities.<p></p>

          In the future, there is the opportunity for self-driving cars to be widespread. And they may even become the
          main source of transportation worldwide. This also poses a major ethical risk.<p></p>

          Although it is possible to train a machine to always choose to protect the human in every scenario what about
          the cases such as the train dilemma where someone must die.<p></p>

          In the week 7 COMP501 lecture everyone did a quiz based on their ethical dilemmas. We found from that quiz
          that everyone has a slightly different ethical mindset. And that in these ethical dilemmas; humans themselves
          can find a consensus on who to kill and who to save.<p></p>

          If humans themselves can’t reach a consensus on these dilemmas, how will we, as humans, be able to program a
          machine to make the ‘correct’ choice.<p></p>

          I believe that until a solution is found to the ethical dilemmas that can be encountered with self-driving
          cars. They should not be implemented in a widespread fashion without a human being able to take control.<p></p>

          As SML gets more and more advanced, and as it gets closer and closer to mimicking human decision patterns,
          more and more ethical dilemmas show up.<p></p>

          This is why I believe that there should be a worldwide code of ethics for the development of SML. And why
          instead of rushing into these advancements we should take a step back and figure out the ethics behind what we
          are doing before we make a mistake we can’t undo.<p></p>
        </h3>
      </div>
      <!--box-->
    </div>
    <!--content-->
  </div>
  <!--background-->
  <div id="footer">
    <h3 style="font-size:0.9vw;" class="ftext">© Group 1106</h3>
  </div>
  <!--footer-->
</body>

</html>